(window.webpackJsonp=window.webpackJsonp||[]).push([[84],{452:function(s,t,a){"use strict";a.r(t);var n=a(15),e=Object(n.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("p",[s._v("在互联网早期的时候，单体架构就足以支撑起日常的业务需求，大家的所有业务服务都在一个项目里，部署在一台物理机器上")]),s._v(" "),t("p",[s._v("所有的业务包括你的交易系统、会员信息、库存、商品等等都夹杂在一起，当流量一旦起来之后，单体架构的问题就暴露出来了，机器挂了所有的业务全部无法使用了。我们会进行集群部署来处理这个问题")]),s._v(" "),t("p",[s._v("后来随着业务发展，用户越来越多，单机无法承受巨量的 QPS，因此出现了业务拆分，每个服务只负责业务的一部分，我们在维护这一部分业务的时候，需要考虑的问题大同小异，出现高 QPS 拖垮机器的时候，可以从下面的思路去考虑：")]),s._v(" "),t("p",[s._v("1，保证用户请求的数据尽量少：我们可以做一些动静分离等操作，将静态数据放进 CDN\n2，"),t("strong",[s._v("过滤尽可能多的请求")]),s._v("：你会想我一个高 QPS 的系统本来就是为了处理大量请求的，现在却需要让请求数尽量少，这是不是不合理？事实上，用少量资源无论怎么设计，资源的限制就在那里。如果少量资源扛住了大量请求，那一定是丢弃了用户的无效请求。我们可以做一个业务漏斗，逐层校验并且过滤无效请求\n3，"),t("strong",[s._v("依赖尽量少")]),s._v("：能用缓存用缓存，能不调用下游不调用下游。同时也不要相信下游提供的能力，做好降级。这块可以将热点数据放进缓存。如果是写请求，可以先将请求主要内容存下来，并且解析放进 MQ，然后异步的保存额外数据")]),s._v(" "),t("p",[s._v("并发高 qps 的核心优化理念是尽量减少用户到服务端来读数据，或者让他们读更少的数据。链路和数据越多，不确定因素越多，风险越高，大部分秒杀系统只涉及核心数据，并且需要保证并发性")]),s._v(" "),t("h2",{attrs:{id:"高并发"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#高并发"}},[s._v("#")]),s._v(" 高并发")]),s._v(" "),t("p",[s._v("高并发的优化方案无非三种")]),s._v(" "),t("ul",[t("li",[s._v("Scale-out（横向扩展）：分而治之是一种常见的高并发系统设计方法，采用分布式部署的方式把流量分流开，让每个服务器都承担一部分并发和流量。与之相对的是 Scale-up，升级机器性能，比如将4核8g 升级成8核16g")]),s._v(" "),t("li",[s._v("缓存：使用缓存来提高系统的性能，就好比用“拓宽河道”的方式抵抗高并发大流量的冲击。")]),s._v(" "),t("li",[s._v("异步：在某些场景下，未处理完成之前，我们可以让请求先返回，在数据准备好之后再通知请求方，这样可以在单位时间内处理更多的请求")])]),s._v(" "),t("p",[s._v("但是在具体实现方案上可以玩出花来")]),s._v(" "),t("h3",{attrs:{id:"高性能-rpc、业务拆分-微服务架构-与数据库分库分表"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#高性能-rpc、业务拆分-微服务架构-与数据库分库分表"}},[s._v("#")]),s._v(" 高性能 RPC、业务拆分（微服务架构）与数据库分库分表")]),s._v(" "),t("p",[s._v("传统 HTTP 的通信方式性能首先并不太好，大量的请求头之类无效的信息是对性能的浪费，这时候就需要引入诸如 Dubbo 类的 RPC 框架")]),s._v(" "),t("p",[s._v("有小伙伴进行对比测试，DubboRPC 的性能，是 FeignRPC 的性能10倍。我们假设原来来自客户端的 QPS 是9000的话，那么通过负载均衡策略分散到每台机器就是3000，而 FeignHTTPRPC 改为 DubboRPC 之后，接口的耗时缩短了，单体服务和整体的 QPS 就提升了")]),s._v(" "),t("p",[s._v("而 RPC 框架本身一般都自带负载均衡、熔断降级的机制，可以更好的维护整个系统的高可用性")]),s._v(" "),t("p",[s._v("而 Dubbo 的优秀性能源自它的序列化机制和通信协议，框架对于请求头做了很多删减，并且序列化机制和通信协议都可以做切换")]),s._v(" "),t("p",[s._v("针对微服务而言分库本身已经是做过的，如果没做的话说明之前的业务体量不大，一个业务可以支持大多数功能，如果体量大了，需要按业务维度进行拆分，每个业务独立出来负责每个业务自己的功能来分摊 QPS 压力")]),s._v(" "),t("p",[s._v("剩下是分表的方案了，我接触过的分表方案是没有用组件做的，是业务抽了一层出来，对于 ID 的最后一位做分表，也可以参考一致性哈希做分表，水平分表后，表可以存放在不同的 db 中，以此实现了类似负载均衡的效果。对于垂直分表我接触的比较少，毕竟在建表的时候我们应该就考虑到了业务需要以及 BC 范式")]),s._v(" "),t("h3",{attrs:{id:"增加中间层"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#增加中间层"}},[s._v("#")]),s._v(" 增加中间层")]),s._v(" "),t("p",[s._v("处理巨量读请求的时候用 ES，解耦削峰用 MQ，不知道用啥但是想优化系统考虑 Redis")]),s._v(" "),t("p",[s._v("这里的核心思想是将数据放在离用户较近的地方，比如 CDN，是将资源冷热分离，只有涉及到动态变化的数据，需要访问后端的服务，减少请求打到后端的次数，系统所支持的 qps 自然也会提高。这种将资源拆分并且分离的例子在后端也是可以使用的")]),s._v(" "),t("p",[s._v("我在刚开始工作的时候有一个段子，公司的高并发其实是在前端做了一个随机过滤的功能，用户每次点击页面只有百分之五十的概率访问后端接口，其他情况会直接给用户返回系统忙请稍后")]),s._v(" "),t("p",[s._v("虽然这是个笑话，但是大家想一下这样肯定可以增加系统的最大并发量，我们在实际工程的时候肯定不能这么处理，但是可以借鉴这个思路")]),s._v(" "),t("h4",{attrs:{id:"消息队列消峰解耦"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息队列消峰解耦"}},[s._v("#")]),s._v(" 消息队列消峰解耦")]),s._v(" "),t("p",[s._v("对于 MQ 的作用大家都应该很了解了，主要功能：")]),s._v(" "),t("ul",[t("li",[s._v("削峰填谷、解耦")]),s._v(" "),t("li",[s._v("同步转异步的方式，可以降低微服务之间的耦合")])]),s._v(" "),t("p",[s._v("对于一些不需要同步执行的接口，可以通过引入消息队列的方式异步执行以提高接口响应时间。在交易完成之后需要扣库存，然后可能需要给会员发放积分，本质上，发积分的动作应该属于履约服务，对实时性的要求也不高，我们只要保证最终一致性也就是能履约成功就行了")]),s._v(" "),t("p",[s._v("对于这种同类性质的请求就可以走 MQ 异步，也就提高了系统抗压能力了")]),s._v(" "),t("p",[s._v("与此同时需要考虑引入 MQ 的各种问题，比如消息队列满了怎么办，数据量太多我们接受不过来怎么办")]),s._v(" "),t("h4",{attrs:{id:"缓存-将数据放到尽可能离用户近的地方"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#缓存-将数据放到尽可能离用户近的地方"}},[s._v("#")]),s._v(" 缓存（将数据放到尽可能离用户近的地方）")]),s._v(" "),t("p",[s._v("缓存作为高性能的代表，在某些特殊业务可能承担90%以上的热点流量，这里的缓存不单单指的是 redis 分布式缓存，在业务链路上涉及到的任何缓存都是我们优化系统的关键，比如浏览器缓存、CDN 缓存、本地缓存、分布式缓存等，这些缓存起到的作用就是将数据放到尽可能离用户近的地方，让更少的用户请求走完完整的链路，让我们整个业务形成一个流量漏斗，这个漏斗做的越优秀，我们系统可以承载的 QPS 越大")]),s._v(" "),t("p",[s._v("对于一些活动比如秒杀这种并发 QPS 可能几十万的场景，引入缓存事先预热可以大幅降低对数据库的压力，10万的 QPS 对于单机的数据库来说可能就挂了，但是对于如 redis 这样的缓存来说就完全不是问题")]),s._v(" "),t("p",[s._v("以秒杀系统举例，活动预热商品信息可以提前缓存提供查询服务，库存数据可以提前缓存，下单流程可以完全走缓存扣减，秒杀结束后再异步写入数据库，采用这种异步读写穿透模式数据库承担的压力就小的太多了")]),s._v(" "),t("p",[s._v("同时还可以用来做分布式锁和普通的读缓存，在处理性能问题时引入缓存一般错不了。但是引入缓存主要考虑缓存三大问题以及数据不一致问题")]),s._v(" "),t("h4",{attrs:{id:"es-查询优化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#es-查询优化"}},[s._v("#")]),s._v(" ES 查询优化")]),s._v(" "),t("p",[s._v("我们分库分表后，用户需要根据一些字段查询自己的数据，有可能这些字段不在一个库中，这时候我们就需要使用 ES 做查询优化了，他底层查询速度因为使用了倒排索引拆分执行导致非常快，是标准的数据拆分后的聚合方案")]),s._v(" "),t("p",[s._v("对于 ES、redis 这种天然支持分布式架构的中间件来说，如果整个集群都挂掉了，我们需要启动从集群，我们有两个机房，分别是机房 A 和机房 B。我们把 ES 主集群部署在机房 A，把 ES 备集群部署在机房 B。会员系统的读写都在 ES 主集群，通过 MQ 将数据同步到 ES 备集群")]),s._v(" "),t("p",[s._v("此时，如果 ES 主集群崩了，通过统一配置，将会员系统的读写切到机房 B 的 ES 备集群上，这样即使 ES 主集群挂了，也能在很短的时间内实现故障转移，确保会员系统的稳定运行")]),s._v(" "),t("p",[s._v("最后，等 ES 主集群故障恢复后，打开开关，将故障期间的数据同步到 ES 主集群，等数据同步一致后，再将会员系统的读写切到 ES 主集群。这么做也是主从架构，不过是主从集群而已，维持了集群的高可用性")]),s._v(" "),t("h3",{attrs:{id:"负载均衡和读写分离"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#负载均衡和读写分离"}},[s._v("#")]),s._v(" 负载均衡和读写分离")]),s._v(" "),t("p",[s._v("对于整个系统而言，最终所有的流量的查询和写入都落在数据库上，数据库是支撑系统高并发能力的核心，但是一台 db 所能支持的 qps 上限大概只有1w左右")]),s._v(" "),t("p",[s._v("怎么降低数据库的压力，提升数据库的性能是支撑高并发的基石。主要的方式就是通过读写分离来解决这个问题")]),s._v(" "),t("p",[s._v("对于整个系统而言，流量应该是一个漏斗的形式。比如我们的日活用户 DAU 有20万，实际可能每天来到提单页的用户只有3万 QPS，最终转化到下单支付成功的 QPS 只有1万")]),s._v(" "),t("p",[s._v("那么对于系统来说读是大于写的，这时候可以通过读写分离的方式来降低数据库的压力")]),s._v(" "),t("p",[s._v("与此同时，需要考虑到读写分离带来的数据不一致问题，我就遇到过由于 DB 没有设置为全同步，导致营运导入两批账号后，发现账户的机构数据错误的情况。虽然这种问题发生的概率比较小，当时我们也可以做一些处理，比如修改是上分布式锁，修改结束后不释放锁，而是等待一会解锁，来确保主从已经全同步了")]),s._v(" "),t("p",[s._v("常见的负载均衡算法有随机、轮询、加权随机、加权轮询、最小连接数、一致性 hash 等等")]),s._v(" "),t("h3",{attrs:{id:"高并发写优化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#高并发写优化"}},[s._v("#")]),s._v(" 高并发写优化")]),s._v(" "),t("p",[s._v("高 QPS 下写流量过大，会导致 db 扛不住，尤其是 db 强制写主库，主从同步需要一定时间，这就导致就算数据库使用了事务加全同步的方式，还是可能出现修改丢失的问题，因此我们可以做以下优化：")]),s._v(" "),t("ul",[t("li",[s._v("引入 mq 异步写入")]),s._v(" "),t("li",[s._v("将一段时间的数据存起来（可以存到 redis、本地缓存等地方，甚至可以存到 mq 中然后批量读取，这一条优化建议与第一条不冲突），然后批量写入")]),s._v(" "),t("li",[s._v("如果是秒杀场景，则需要把秒杀库存数据先写到 redis（因为需要频繁写入，redis 的抗压能力比 db 更强）中，然后使用 lua 脚本、上分布式锁、watch 乐观锁配合事务等方式实现库存扣减的原子操作")]),s._v(" "),t("li",[s._v("如果是秒杀场景，我们可以将库存按均分配到多台机器上，每个机器缓存一部分库存，这样就利用网关做了一个分流的功能。这个库存也可以分到 reids 中")])]),s._v(" "),t("h2",{attrs:{id:"高可用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#高可用"}},[s._v("#")]),s._v(" 高可用")]),s._v(" "),t("p",[s._v("关于高可用的内容可能是架构组的同学考虑的比较多的事情，但是我们平时工作的过程中或多或少接触过，同时高可用也是设计高 QPS 系统的必要一环")]),s._v(" "),t("h3",{attrs:{id:"故障预防"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#故障预防"}},[s._v("#")]),s._v(" 故障预防")]),s._v(" "),t("p",[s._v("在服务之间我们一般从下面几点出发优化应用")]),s._v(" "),t("ul",[t("li",[s._v("熔断：比如营销服务挂了或者接口大量超时的异常情况，不能影响下单的主链路，涉及到积分的扣减一些操作可以在事后做补救。熔断之后降级方案就是短时间内不再调用服务，等到营销恢复之后再调用")]),s._v(" "),t("li",[s._v("限流：对突发如大促秒杀类的高并发，如果一些接口不做限流处理，可能直接就把服务打挂了，针对每个接口的压测性能的评估做出合适的限流尤为重要。在网关层，做一些令牌桶、漏桶、滑动窗口、固定窗口算法即可")]),s._v(" "),t("li",[s._v("降级：降级一般在代码内部做，先梳理出系统的强弱依赖，对于一些弱依赖调用失败的情况，我们可以返回默认的回复。这里我们应当对系统的强弱依赖做分类，强依赖应当熔断限流，防止打跨下游机器，弱依赖进行降级")]),s._v(" "),t("li",[s._v("隔离：这里指的是重点流量或者高消耗客户的流量隔离，为他们专门搭建 VIP 集群，保证流量高可用")]),s._v(" "),t("li",[s._v("超时：服务调用超时需要做额外处理")]),s._v(" "),t("li",[s._v("持久化机制：让崩溃机器快速恢复，其中包括冷备热备双活等")])]),s._v(" "),t("h3",{attrs:{id:"集群部署"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#集群部署"}},[s._v("#")]),s._v(" 集群部署")]),s._v(" "),t("ul",[t("li",[s._v("集群部署："),t("strong",[s._v("利用冗余消除单点是高可用基石")]),s._v("。无论是主从部署、多主部署、读写分离，都或多或少优化了集群的高可用性")]),s._v(" "),t("li",[s._v("负载均衡：这里的负载均衡是指高可用负载，某台机器出现故障后可以快速路由为其他机器")])]),s._v(" "),t("p",[s._v("集群部署中，有分冷备热备同城双活异地双活等部署方式，需要按照真实的线上问题去部署不同的集群")]),s._v(" "),t("p",[s._v("比如跨机房读取数据的情况，B 机房中的应用就会跨机房读取 A 机房的数据，如下图所示。如果 B 和 A 相隔很远的话，这个时延就很高了\n"),t("img",{attrs:{src:"https://i-blog.csdnimg.cn/direct/5267764e07804e01ac95f6e1f90197f6.png",alt:"在这里插入图片描述"}})]),s._v(" "),t("ul",[t("li",[s._v("同城双机房专线延迟在1ms~3ms之间")]),s._v(" "),t("li",[s._v("就国内的异地双机房专线延迟在50ms之内")]),s._v(" "),t("li",[s._v("国际异地双机房专线的网络延迟一般会在100ms~200ms")])]),s._v(" "),t("p",[s._v("因此两个机房中，每个机房会承担一部分流量，涉及到服务的调用和数据读写时，尽量在本机房内完成，如果是 RPC 调用，不同机房的 RPC 服务可以向注册中心注册不同的服务分组，不同机房的 RPC 消费者只订阅本机房内的服务分组")]),s._v(" "),t("p",[s._v("这样就可以实现 RPC 调用尽量发生在本机房内。如果是写数据，则可以向一个机房写数据，而实时同步到另一个机房。这样解决了时延问题，也解决了容灾问题\n"),t("img",{attrs:{src:"https://i-blog.csdnimg.cn/direct/364b619cba0448a49fb9d6c27fac1d2e.png",alt:"在这里插入图片描述"}})]),s._v(" "),t("h3",{attrs:{id:"自动恢复与人工处理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#自动恢复与人工处理"}},[s._v("#")]),s._v(" 自动恢复与人工处理")]),s._v(" "),t("p",[s._v("自动化是效率之源")]),s._v(" "),t("ul",[t("li",[s._v("自动选主：中间件崩溃后都有自动选主自动恢复的功能")]),s._v(" "),t("li",[s._v("预案：一般来说，就算是有统一配置中心，在业务的高峰期也是不允许做出任何的变更的，但是通过配置合理的预案可以在紧急的时候做一些修改")]),s._v(" "),t("li",[s._v("监控和报警")])]),s._v(" "),t("h2",{attrs:{id:"高性能"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#高性能"}},[s._v("#")]),s._v(" 高性能")]),s._v(" "),t("p",[s._v("高性能支持了高并发，常见的高性能优化如下：")]),s._v(" "),t("ul",[t("li",[s._v("池化：后台开发过程中你一定离不开各种池子：内存池、连接池、线程池、对象池。内存、连接、线程这些都是资源，创建线程、分配内存、数据库连接这些操作都有一个特征， 那就是创建和销毁过程都会涉及到很多系统调用或者网络 IO。 每次都在请求中去申请创建这些资源，就会增加请求处理耗时，但是如果我们用一个 容器（池） 把它们保存起来，下次需要的时候，直接拿出来使用，避免重复创建和销毁浪费的时间")]),s._v(" "),t("li",[s._v("IO 多路复用和零拷贝：netty 性能好就是用了这两个优化")]),s._v(" "),t("li",[s._v("多线程：充分利用 CPU 资源，但是使用多线程又必须额外拿出一些资源处理线程安全问题")]),s._v(" "),t("li",[s._v("批量处理：在涉及到网络连接、IO 等情况时，将操作批量进行处理能够有效提高系统的传输速率和吞吐量，kafka 就是这么做的，生产者发送消息时，可以将消息合并发送，消费者拉取消息时，也可以将消息批量拉取")]),s._v(" "),t("li",[s._v("sql 优化以及算法优化：这属于业务逻辑优化")]),s._v(" "),t("li",[s._v("扩容：扩容治百病，重启解千愁")])]),s._v(" "),t("h2",{attrs:{id:"额外考量"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#额外考量"}},[s._v("#")]),s._v(" 额外考量")]),s._v(" "),t("h3",{attrs:{id:"压测"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#压测"}},[s._v("#")]),s._v(" 压测")]),s._v(" "),t("p",[s._v("一个高性能的系统，一定是需要压测看性能的。根据压测结果可以推断线上运行的危险值在哪，方便我们即使推断定位问题，以及及时扩容")]),s._v(" "),t("div",{staticClass:"language-linux line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("## 使用wrk进行压测\n## 预热阶段\nwrk -t4 -c100 -d30s --latency http://api.example.com/product/1\n\n## 正式压测\nwrk -t12 -c1000 -d300s --latency http://api.example.com/product/1\n\n## 混合场景压测\nvegeta attack -duration=300s -rate=2000 \\\n  -targets=targets.txt | vegeta report\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br")])]),t("h3",{attrs:{id:"可观测性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#可观测性"}},[s._v("#")]),s._v(" 可观测性")]),s._v(" "),t("p",[s._v("监控项应该考虑以下几点：")]),s._v(" "),t("p",[s._v("应用层")]),s._v(" "),t("ul",[t("li",[s._v("QPS/TPS")]),s._v(" "),t("li",[s._v("响应时间(P99/P95)")]),s._v(" "),t("li",[s._v("错误率或者异常指标")]),s._v(" "),t("li",[s._v("JVM 指标")]),s._v(" "),t("li",[s._v("机器 CPU、内存使用率，如果过高可能需要考虑扩容")])]),s._v(" "),t("p",[s._v("Redis")]),s._v(" "),t("ul",[t("li",[s._v("内存使用率")]),s._v(" "),t("li",[s._v("连接数")]),s._v(" "),t("li",[s._v("命中率")]),s._v(" "),t("li",[s._v("慢查询")])]),s._v(" "),t("p",[s._v("MySQL")]),s._v(" "),t("ul",[t("li",[s._v("活跃连接数")]),s._v(" "),t("li",[s._v("InnoDB缓冲池命中率")]),s._v(" "),t("li",[s._v("慢SQL数")]),s._v(" "),t("li",[s._v("主从延迟")])]),s._v(" "),t("p",[s._v("做好全面的告警配置")]),s._v(" "),t("h3",{attrs:{id:"分布式-id"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#分布式-id"}},[s._v("#")]),s._v(" 分布式 ID")]),s._v(" "),t("p",[s._v("推荐使用雪花算法，当然用 UUID 或者 redis、mysql 的步长机制也可以")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 雪花算法实现")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("SnowflakeIdGenerator")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("private")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("long")]),s._v(" datacenterId"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("private")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("long")]),s._v(" workerId"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("private")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("long")]),s._v(" sequence "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0L")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("private")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("long")]),s._v(" lastTimestamp "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1L")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("synchronized")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("long")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("nextId")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("long")]),s._v(" timestamp "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("timeGen")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        \n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("timestamp "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" lastTimestamp"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("throw")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("RuntimeException")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"时钟回拨"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        \n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("timestamp "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" lastTimestamp"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            sequence "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("sequence "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4095")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("sequence "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                timestamp "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("tilNextMillis")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("lastTimestamp"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            sequence "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0L")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        \n        lastTimestamp "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" timestamp"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        \n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("timestamp "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1288834974657L")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n               "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("datacenterId "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("17")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n               "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("workerId "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("\n               sequence"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br")])]),t("h2",{attrs:{id:"总结"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[s._v("#")]),s._v(" 总结")]),s._v(" "),t("p",[s._v("其实可以看到，怎么设计高并发系统这个问题本身他是不难的，无非是基于你知道的知识点，从物理硬件层面到软件的架构、代码层面的优化，使用什么中间件来不断提高系统的抗压能力")]),s._v(" "),t("p",[s._v("但是这个问题本身会带来更多的问题，微服务本身的拆分带来了分布式事务的问题，http、RPC 框架的使用带来了通信效率、路由、容错的问题，MQ 的引入带来了消息丢失、积压、事务消息、顺序消息的问题，缓存的引入又会带来一致性、雪崩、击穿的问题")]),s._v(" "),t("p",[s._v("数据库的读写分离、分库分表又会带来主从同步延迟、分布式 ID、事务一致性的问题，而为了解决这些问题我们又要不断的加入各种措施熔断、限流、降级、离线核对、预案处理等等来防止和追溯这些问题")]),s._v(" "),t("p",[s._v("额外提一下秒杀系统，秒杀本质上就是一个满足大并发、高性能和高可用的分布式系统，需要处理并发读和并发写，因此秒杀的解决方案在本章中也有，除了并发写中有一个并发安全问题需要处理以外，秒杀的设计完全可以按照本章总结的内容来")])])}),[],!1,null,null,null);t.default=e.exports}}]);