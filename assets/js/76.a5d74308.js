(window.webpackJsonp=window.webpackJsonp||[]).push([[76],{439:function(v,_,t){"use strict";t.r(_);var a=t(15),e=Object(a.a)({},(function(){var v=this,_=v._self._c;return _("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[_("p",[v._v("NLP（Natuarl Language Processing）是人工智能的一个分支，中文名"),_("strong",[v._v("自然语言处理")]),v._v("，专注于处理和理解人类使用的自然语言。它涵盖了多个子领域，如文本分类、情感分析、机器翻译、问答系统、语音识别、语义解析等。粗糙一点理解，就是可以和人类沟通的 AI")]),v._v(" "),_("h2",{attrs:{id:"技术范式"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#技术范式"}},[v._v("#")]),v._v(" 技术范式")]),v._v(" "),_("p",[v._v("NLP 的常见的相关技术如下：\n"),_("img",{attrs:{src:"image/image-8.png",alt:""}})]),v._v(" "),_("h3",{attrs:{id:"监督学习"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#监督学习"}},[v._v("#")]),v._v(" 监督学习")]),v._v(" "),_("p",[v._v("监督学习是指根据已有的数据集，知道输入和输出结果之间的关系。根据这种已知的关系，训练得到一个最优的模型")]),v._v(" "),_("p",[v._v("在监督学习中训练数据既有"),_("strong",[v._v("特征")]),v._v("（feature，输入的变量，有可能有几千万个）又有"),_("strong",[v._v("标签")]),v._v("（label，需要预测的事务，比如输入特征黑白相间、名字带熊、毛茸茸的，输出的标签为熊猫），通过训练，"),_("strong",[v._v("让机器可以自己找到特征和标签之间的联系")]),v._v("，在面对只有特征没有标签的数据时，可以判断出标签")]),v._v(" "),_("p",[v._v("eg：经典的机械学习入门案例，波士顿房价预测，就是监督学习，这题算的上是算法届的 hello world")]),v._v(" "),_("p",[v._v("波士顿房地产市场竞争激烈，而你想成为该地区最好的房地产经纪人。为了更好地与同行竞争，你决定运用机器学习的一些基本概念，帮助客户为自己的房产定下最佳售价。幸运的是，你找到了波士顿房价的数据集，里面聚合了波士顿郊区包含多个特征维度的房价数据。你的任务是用可用的工具进行统计分析，并基于分析建立优化模型。这个模型将用来为你的客户评估房产的最佳售价\n"),_("img",{attrs:{src:"image-9.png",alt:"、"}}),v._v(" "),_("img",{attrs:{src:"image/image-10.png",alt:""}}),v._v("\n监督学习所使用的技术：")]),v._v(" "),_("p",[v._v("1："),_("strong",[v._v("线性回归")]),v._v("算法，线性回归是一种用于建立自变量（输入）和因变量（输出）之间线性关系的模型，其重点是")]),v._v(" "),_("ul",[_("li",[v._v("通过提供数据训练模型，让模型得到自变量和因变量对应的映射关系")]),v._v(" "),_("li",[v._v("映射关系是连续且线性的")])]),v._v(" "),_("p",[v._v("2：决策树算法，该算法用于解决分类和回归问题。它通过构建一棵树形结构来进行决策，每个内部节点表示一个特征或属性（色泽和触感），每个叶节点表示一个类别或一个数值（好瓜、坏瓜）\n"),_("img",{attrs:{src:"image-11.png",alt:"alt text"}}),v._v("\n决策树算法的基本步骤如下：")]),v._v(" "),_("ul",[_("li",[v._v("特征选择：根据某个准则选择最佳的特征作为当前节点的划分依据。常用的特征选择准则包括信息增益、信息增益比、基尼指数等")]),v._v(" "),_("li",[v._v("决策树生成：根据特征选择的结果，递归地生成决策树的内部节点和叶节点。每个内部节点表示一个特征，根据该特征的取值将样本划分到不同的子节点中")]),v._v(" "),_("li",[v._v("决策树剪枝：为了防止过拟合，可以进行决策树的剪枝操作。剪枝过程可以通过预剪枝或后剪枝来实现。预剪枝是在决策树生成过程中进行判断，如果划分不再显著提高性能，则停止划分。后剪枝是在决策树生成之后，通过剪枝操作来减小决策树的复杂度")])]),v._v(" "),_("p",[v._v("3：朴素贝叶斯算法是基于贝叶斯定理和特征条件独立假设的分类算法。它假设特征之间是相互独立的，然后根据已知的特征和类别的条件概率，计算待分类样本属于每个类别的概率，并选择概率最大的类别作为预测结果")]),v._v(" "),_("p",[v._v("4：K 近邻算法就是如果一个样本附近的 k 个最近（即特征空间中最邻近）样本的大多数属于某一个类别，则该样本也属于这个类别")]),v._v(" "),_("h3",{attrs:{id:"无监督学习"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#无监督学习"}},[v._v("#")]),v._v(" 无监督学习")]),v._v(" "),_("p",[v._v("我们不知道数据集中数据、特征之间的关系，而是要根据聚类或一定的模型得到数据之间的关系，这种情况就需要使用无监督学习了")]),v._v(" "),_("p",[v._v("在无监督学习中数据只有特征无标签，是一种机器学习的训练方式，它本质上是一个统计手段，让模型在没有标签的数据里发现各个数据之间的联系。比起监督学习，无监督学习更像是自学，让机器学会自己做事情\n"),_("img",{attrs:{src:"image/image-12.png",alt:""}}),v._v("\n举个例子：左图是无监督学习的过程，虽然数据被分成了两类，但是没有对应的数据标签，统一用蓝色的圆点表示，这更像是把具有相同的特征的数据聚集在一起，所以无监督学习实现分类的算法又叫做"),_("strong",[v._v("聚类")]),v._v("，而有监督学习则更向是"),_("strong",[v._v("分类")]),v._v("。右图是监督学习中二分类的过程，标签在图中体现为三角和圆")]),v._v(" "),_("p",[v._v("在执行聚类算法后，数据可能会根据算法，分为很多类，如果数据是二维属性的，划分数据的可能是一条线，如果数据是三维属性的，划分数据的可能是一个切面，如果数据是 n 维的，那划分数据的是 n-1 维的超平面")]),v._v(" "),_("p",[v._v("除了无监督学习之外还有半监督学习，半监督学习的目标是利用同时包含有标签和无标签的数据来构建一个模型，使得模型能够在测试阶段更好地泛化到新的、未见过的数据")]),v._v(" "),_("p",[v._v("无监督学习所使用的技术：")]),v._v(" "),_("p",[v._v("1，K 均值聚类是一种常用的聚类算法，用于将数据集划分为 K 个不重叠的簇。每个簇代表一个数据的集合，其中相似的数据被分配到同一个簇中，K-Means 算法的基本思想是通过迭代优化的方式来找到最优的簇划分。具体步骤如下：")]),v._v(" "),_("ul",[_("li",[v._v("定义 K 个重心。一开始这些重心是随机的（也有一些更加有效的用于初始化重心的算法）")]),v._v(" "),_("li",[v._v("寻找最近的重心并且更新聚类分配。将每个数据点都分配给这 K 个聚类中的一个。每个数据点都被分配给离它们最近的重心的聚类。这里的「接近程度」的度量是一个超参数——通常是欧几里得距离（Euclidean distance）")]),v._v(" "),_("li",[v._v("将重心移动到它们的聚类的中心。每个聚类的重心的新位置是通过计算该聚类中所有数据点的平均位置得到的")]),v._v(" "),_("li",[v._v("重复第 2 和 3 步，直到每次迭代时重心的位置不再显著变化（即直到该算法收敛）")])]),v._v(" "),_("p",[v._v("2，层次聚类。如果你不知道应该分为几类，那么层次聚类就比较适合了。层次聚类会构建一个多层嵌套的分类，类似一个树状结构\n"),_("img",{attrs:{src:"image/image-13.png",alt:""}}),v._v("\n层次聚类的步骤如下：")]),v._v(" "),_("ul",[_("li",[v._v("首先从 N 个聚类开始，每个数据点一个聚类。")]),v._v(" "),_("li",[v._v("将彼此靠得最近的两个聚类融合为一个。现在你有 N-1 个聚类。")]),v._v(" "),_("li",[v._v("重新计算这些聚类之间的距离。")]),v._v(" "),_("li",[v._v("重复第 2 和 3 步，直到你得到包含 N 个数据点的一个聚类。")]),v._v(" "),_("li",[v._v("选择一个聚类数量，然后在这个树状图中划一条水平线。")])]),v._v(" "),_("h3",{attrs:{id:"自监督学习"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#自监督学习"}},[v._v("#")]),v._v(" 自监督学习")]),v._v(" "),_("p",[v._v("LLM 的预训练是无监督学习，更准确地说，它是自监督学习（Self-Supervised Learning），属于无监督学习的一种特殊形式。以 GPT 为例，我们给定一段文本，让模型预测下一个词（语言建模任务）")]),v._v(" "),_("ul",[_("li",[v._v('输入："今天天气很___"')]),v._v(" "),_("li",[v._v('目标：让模型预测 "好"（无需人工标注，答案来自文本本身）')])]),v._v(" "),_("p",[v._v("因为这种方式无需人工标注，标签是文本中自带的，只不过给模型的时候把一个词给挖掉了，所以是无监督学习下的一类，这种训练方式数据利用效率高，所有文本均可用于训练")]),v._v(" "),_("p",[v._v("这个说专业一点叫"),_("strong",[v._v("掩码预测")])]),v._v(" "),_("h2",{attrs:{id:"分词"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#分词"}},[v._v("#")]),v._v(" 分词")]),v._v(" "),_("p",[v._v("大模型的分词器是将文本拆分为模型可处理的基本单元的核心组件，直接影响模型的理解能力和生成效果，我们简单介绍一下主流的分词器")]),v._v(" "),_("p",[v._v("1，基于词的分词（Word-based），做法是按空格或词典切分完整单词。这么做的话词表庞大，因为需覆盖所有单词。并且无法处理未登录词，万一出现什么新词需要额外登录一下")]),v._v(" "),_("p",[v._v("2，基于字符的分词，一般不会这么干")]),v._v(" "),_("p",[v._v("3，子词分词（Subword），"),_("strong",[v._v("高频词保留完整，低频词拆分为子词")]),v._v("。是目前最主流的方法，具体做法为 Byte Pair Encoding ("),_("strong",[v._v("BPE")]),v._v(")，BPE 会统计所有相邻字符对频率（举例来说，“h”+“e”在“hello，java；hello es；hello nlp”中出现3次，BPE 会记录下来），然后合并最高频字符对（“h”+“e”→“he”），更新词表，重复直到词表达预定大小")]),v._v(" "),_("h2",{attrs:{id:"embedding-嵌入"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#embedding-嵌入"}},[v._v("#")]),v._v(" Embedding（嵌入）")]),v._v(" "),_("p",[v._v("这里说个题外话，上文说：聚类算法可以将一些 n 维的数据聚集成一个簇，来让计算机理解数据的相似性，那我们面对 GPT 输入的都是文字，GPT 怎么能做到对这些单词聚类的呢？只要将文字转化成向量，我们就可以使用上面的聚类算法让计算机理解我们说的话了。那么我们将问题简单化，如果我输入的是一段文字，或者一个单词，计算机是怎么将数据转换成 n 维的向量的呢")]),v._v(" "),_("p",[v._v("Embedding 意思是嵌入，文本向量化（Text Embedding）就是将文本数据（词、句子、文档）表示成向量的方法。词向量化将词转为二进制或高维实数向量，句子和文档向量化则将句子或文档转为数值向量。总之，Embedding 向量不仅仅是对物体进行简单编号或标识，而是"),_("strong",[v._v("通过特征抽象和编码，在尽量保持物体间相似性的前提下，将物体映射到一个高维特征空间中")]),v._v("。Embedding 向量能够捕捉到物体之间的相似性和关系，在映射到高维特征空间后，相似的物体在空间中会聚集在一起，而不同的物体会被分隔开\n"),_("img",{attrs:{src:"image/image-14.png",alt:""}}),v._v("\n将离散的文字信息（如单词）转换成连续的向量数据。这样，语义相似的词在向量空间中位置相近，并通过高维度捕捉语言的复杂性。语义上相近的单词在向量空间中被映射到相近的位置。大模型使用了很多的维度（有些模型可能只有几千，有些模型也可能有数十万）来表示人类语言的复杂度")]),v._v(" "),_("p",[v._v("这么说可能比较抽象，我们举个例子来说明降维和聚类：")]),v._v(" "),_("p",[v._v("假设我们正在构建一个非常简单的单词向量模型，其中每个单词都被表示为一个四维向量，这里的维度代表了某种抽象的概念，比如性别、王室地位、战斗能力和智慧。我们将使用女王、国王、皇后和士兵作为示例单词")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("女王")]),v._v("：我们可以将其表示为向量 [1, 1, 0, 1]，其中第一个1表示女性，第二个1表示王室成员，0表示战斗能力较弱，1表示智慧程度")]),v._v(" "),_("li",[_("strong",[v._v("国王")]),v._v("：向量为 [0, 1, 0, 1]，0表示男性，1表示王室成员，0表示战斗能力较弱，1表示智慧程度")]),v._v(" "),_("li",[_("strong",[v._v("皇后")]),v._v("：向量为 [1, 1, 0, 0]，与女王相似，只是在这里我们用0表示她的智慧程度可能与女王不同")]),v._v(" "),_("li",[_("strong",[v._v("士兵")]),v._v("：向量为 [0, 0, 1, 0]，0表示男性，0表示不是王室成员，1表示战斗能力强，0表示智慧程度")])]),v._v(" "),_("p",[v._v("我们可以让计算机使用一些聚类算法来比较上面四个的相似程度，比如通过一个最简单的聚类算法：比较向量中同一列相同的个数最多，我们发现女王和国王、女王和皇后的相似程度最高")]),v._v(" "),_("p",[v._v("GPT 会根据这种方式，去理解用户的意图，当用户输入一些完全不相关的话时，模型也可以理解并指正，eg：")]),v._v(" "),_("ul",[_("li",[v._v("输入：我认为意大利面应该伴42号混泥土")]),v._v(" "),_("li",[v._v("输出：看起来你可能是在开玩笑或者引用某种幽默的说法，但实际上，意大利面和42号混凝土是两种完全不相关的东西。意大利面是一种源自意大利的传统食物，通常与各种酱料搭配食用，如番茄酱、奶油酱、肉酱或是橄榄油和大蒜等。  而42号混凝土（实际上混凝土没有“42号”这种说法，可能是参考了《银河系漫游指南》中的“生命、宇宙以及一切的答案是42”，这里做幽默解读）是指建筑材料中的一种，用于建筑和工程中，显然与食物无关，更不用说与意大利面一起食用了")])]),v._v(" "),_("p",[v._v("这就是计算机可以理解语意的原理，这同时也是向量库检索的原理。现实生产环境中算法会更加复杂，在将单词、句子、excel、word 转换为向量（嵌入层所处理的事情，会使用降维算法，主要处理将数据降维成向量）以及比较向量近似程度（聚类算法所处理的事情）两个算法中有很深的钻研空间")]),v._v(" "),_("h2",{attrs:{id:"神经网络"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#神经网络"}},[v._v("#")]),v._v(" 神经网络")]),v._v(" "),_("p",[v._v("上面说监督学习会学习输入和输出之间的映射关系。监督学习可以分为两大类：基于神经网络的方法和非神经网络的方法。这两类方法在原理、结构和应用场景上有一些显著的区别，目前的 LLM 大模型，大多都是用神经网络的方式构建的")]),v._v(" "),_("p",[_("strong",[v._v("为什么要用神经网络")]),v._v("？因为我们要解决的问题变复杂了。比如识别一张图是不是猫，这不是面积->房价这种简单直线关系。图片是像素，是海量数据，关系弯弯绕绕。我现在需要让机器不是找一条直线，而是找一大堆可以弯曲的线（激活函数），把它们一层层叠起来，去拟合那些弯弯绕绕的关系")]),v._v(" "),_("p",[v._v("神经网络是一种受生物神经系统启发的计算模型，由大量互连的节点（神经元）组成。"),_("strong",[v._v("这些节点通过多层结构连接，每一层都对输入数据进行变换，最终输出预测结果")]),v._v("。这种技术适用于大规模数据集，计算资源需求较高，包含多层结构，包含大量神经元")]),v._v(" "),_("p",[v._v("在自然语言处理中，递归神经网络，或者说循环神经网络（RNN）、Transformer 等用于文本分类、机器翻译、情感分析等。接下来很简单的聊一下他们的原理以及能做什么")]),v._v(" "),_("p",[v._v("首先了解一下神经网络的构建原理，它起源于很简单的函数，比如 y = ax + b，我们给定一组 x，和 y，让模型给我们猜出 a 和 b 的值，这个猜的结果就是模型的输出，让模型猜对的过程就是预训练和微调")]),v._v(" "),_("p",[v._v("举例说明：")]),v._v(" "),_("p",[v._v('1，Masked Language Modeling （MLM）：随机遮盖15%的 token，预测被遮盖的，示例："我喜欢吃[MASK]果" → 预测"苹"')]),v._v(" "),_("p",[v._v('2，Causal Language Modeling （CLM）：预测下一个 token。示例："今天天气很好，" → 预测"我"')]),v._v(" "),_("p",[v._v("当然现实中的关系往往不是线性的，我们需要使用"),_("strong",[v._v("激活函数")]),v._v("比如 len 啥的。我们每次让模型猜一个值，都使用损失函数来计算这个值和最终结果的差值，差值越小，说明我们越接近正确答案，训练完毕后可能会遇到欠拟合和过拟合的问题，下面是一个简单的激活函数\n"),_("img",{attrs:{src:"https://i-blog.csdnimg.cn/direct/aeee3c2e009d43b6bf00f8b7a733d98b.png",alt:"请添加图片描述"}}),v._v("\n当然这只是一个输入神经元和一个输出神经元，真实的情况可能会感觉复杂，比如下图，有多个中间层（卷积层、池化层、全连接层），多个输出和多个输入：\n"),_("img",{attrs:{src:"https://i-blog.csdnimg.cn/direct/e6e0fa47a80146bda468068dc8feaf07.png",alt:"请添加图片描述"}}),v._v("\n上面这些基础了解完毕后，我们结合上文中提到的嵌入知识，我们可以将一个单词，升纬成一个多纬向量，这个多维向量的每个纬度的值，可以理解成神经元的多个入参，我们可以将这个单词输入，然后得到一个结果")]),v._v(" "),_("p",[v._v("RNN 可以用于文本分类任务，例如情感分析，其解决的问题，是一句话输入输入层时，输入层不知道每个词直接的关系，并且一句话是可变长的，但是模型的输入层一般都是固定的，我们怎么让一个可变长的话转换成一组长度固定的输入呢")]),v._v(" "),_("p",[v._v("给定一段文本，RNN 会逐词处理，并且将上一个处理的单词，额外添加进下一个单词的入参中，让本单词的输入带有上一个单词的信息，以此让模型知道上文说了什么\n"),_("img",{attrs:{src:"image/image-15.png",alt:""}}),v._v(" "),_("strong",[v._v("在处理长序列时，RNN 的梯度可能会变得非常小（消失）或非常大（爆炸），导致训练困难")]),v._v("。eg：")]),v._v(" "),_("ul",[_("li",[v._v('输入序列：["The", "cat", "sat", "on", "the", "mat"]')]),v._v(" "),_("li",[v._v("处理过程：RNN 从左到右逐词处理，每个时间都更新隐藏状态。最终的隐藏状态用于分类。如果句子很长，RNN 可能会忘记最前面的单词，导致分类不准确")])]),v._v(" "),_("p",[v._v("在图像识别 cv 领域，我们有类似的操作：CNN 卷积神经网络的模型，它的输入是一个图像，卷积是将图像的一个像素块，卷成一个向量，这么做也是为了将上下文信息收集到一个向量中，然后做处理\n"),_("img",{attrs:{src:"image-16.png",alt:"层级"}})]),v._v(" "),_("h2",{attrs:{id:"强化学习"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#强化学习"}},[v._v("#")]),v._v(" 强化学习")]),v._v(" "),_("p",[v._v("强化学习是让一个智能体在环境中通过尝试和错误来学习行为策略。智能体通过与环境进行交互，根据奖励信号来调整其行为策略，以达到最大化累积奖励的目标。强化学习和监督学习、无监督学习 最大的不同就是不需要大量的数据喂养，而是通过自己不停的尝试来学会某些技能")]),v._v(" "),_("p",[v._v("具体方式是，我们先使用一些数据来训练模型，然后给他一些任务，对于他的执行结果，我们会返回一个奖励信号，表示他执行该任务的好坏程度，下一次模型执行类似任务时，会根据奖励信号更新其策略")]),v._v(" "),_("p",[v._v("比如在围棋界有一个很出名的事情，AlphaGo Master 击败李世石，使用强化学习的 AlphaGo Zero 仅花了40天时间，就击败了自己的前辈 AlphaGo Master")]),v._v(" "),_("p",[v._v("强化学习的本质是通过奖励信号优化行为。目标是让模型学会最大化奖励函数的累计值，并且我们只"),_("strong",[v._v("提供模型与环境的交互，无固定输入-输出对，只有试错反馈")]),v._v("，因此和微调不太一样，微调是什么后续会介绍")])])}),[],!1,null,null,null);_.default=e.exports}}]);